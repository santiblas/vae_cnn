{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081f2225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [SHAP] fold=1 clf=mlp\n",
      "[WARNING] label_mapping.json no encontrado; se asume CN=0 / AD=1\n",
      "[INFO] [SHAP] X_raw (test) shape=(37, 514) (latentes + 2 metadatos)\n",
      "[INFO] [SHAP] Latentes detectadas en procesado: 512 / 514\n",
      "[WARNING] [SHAP] No hay RAW; uso el procesado: shap_background_data_mlp.joblib\n",
      "[WARNING] [SHAP] Usando KernelExplainer (puede ser lento).\n",
      "[INFO] [SHAP] Resumiendo el background de 100 muestras a 50 centroides para KernelExplainer.\n",
      "100%|███████████████████████████████████████████| 37/37 [00:59<00:00,  1.62s/it]\n",
      "[INFO] [SHAP] Pack guardado: resultados_13_paper/fold_1/interpretability_shap/shap_pack_mlp.joblib\n"
     ]
    }
   ],
   "source": [
    "!python interpretar_fold_paper.py shap \\\n",
    "  --run_dir ./resultados_13_paper \\\n",
    "  --fold 1 \\\n",
    "  --clf mlp \\\n",
    "  --global_tensor_path /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz \\\n",
    "  --metadata_path /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv \\\n",
    "  --channels_to_use 1 2 5 \\\n",
    "  --latent_dim 512 \\\n",
    "  --latent_features_type mu \\\n",
    "  --metadata_features Age Sex \\\n",
    "  --num_conv_layers_encoder 4 \\\n",
    "  --decoder_type convtranspose \\\n",
    "  --dropout_rate_vae 0.2 \\\n",
    "  --intermediate_fc_dim_vae quarter \\\n",
    "  --vae_final_activation tanh \\\n",
    "  --kernel_nsamples 800\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cbc3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [SALIENCY] fold=1 clf=mlp  (pack cargado: shap_pack_mlp.joblib)\n",
      "[INFO] Usando ROI order de resultados_13_paper/roi_order_131.joblib.\n",
      "[INFO] Cargado fichero de anotaciones: /home/diego/Escritorio/limpio/roi_info_master.csv\n",
      "[INFO] [SALIENCY] 50 latentes ponderadas. Ejemplo:\n",
      " latent_idx    weight  importance    feature\n",
      "        479  0.036931    0.005941 latent_479\n",
      "        215  0.036441    0.005862 latent_215\n",
      "         15  0.036379    0.005852  latent_15\n",
      "         67 -0.031471   -0.005063  latent_67\n",
      "        210  0.030629    0.004927 latent_210\n",
      "[INFO] [SALIENCY] Sujetos AD=19  CN=18\n",
      "[INFO] [SALIENCY] Usando método de saliencia: integrated_gradients\n",
      "[INFO] [SALIENCY] Ranking de conexiones ANOTADO guardado: resultados_13_paper/fold_1/interpretability_mlp/ranking_conexiones_ANOTADO_integrated_gradients_top50.csv\n",
      "[INFO] Top 20 conexiones anotadas:\n",
      "      Rank src_AAL3_Name dst_AAL3_Name  Saliency_Score          src_Refined_Network          dst_Refined_Network\n",
      "1816     1          SMAL         CER8L       -0.001357  Salience_VentralAttention_A                   Cerebellum\n",
      "1382     2        F3O_2R           FMR       -0.001335    DefaultMode_VentralMedial     DefaultMode_DorsalMedial\n",
      "2087     3          COBR       OFCLATR        0.001179                 Limbic_B_OFC    DefaultMode_VentralMedial\n",
      "8165     4         CER9L        CER10L       -0.001162                   Cerebellum                   Cerebellum\n",
      "2362     5           FMR          T1AR       -0.001150     DefaultMode_DorsalMedial            Limbic_A_TempPole\n",
      "2629     6           GRL           GRR       -0.001111                 Limbic_B_OFC                 Limbic_B_OFC\n",
      "3578     7       OFCLATR           V1R        0.001061    DefaultMode_VentralMedial               Visual_Central\n",
      "4911     8           V1R       CER4_5R       -0.001059               Visual_Central               Visual_Central\n",
      "5370     9           O1R           GAR       -0.001004            Visual_Peripheral     DefaultMode_DorsalMedial\n",
      "4096    10          CIPL          T1AR       -0.000982     DefaultMode_DorsalMedial            Limbic_A_TempPole\n",
      "3574    11       OFCLATR   PARA_HIPPOR        0.000922    DefaultMode_VentralMedial            Limbic_A_TempPole\n",
      "6535    12           GAR         CER9L       -0.000909     DefaultMode_DorsalMedial                   Cerebellum\n",
      "6101    13           P1R           P2R       -0.000903            DorsalAttention_A                    Control_B\n",
      "3859    14         CINML         CINMR       -0.000890  Salience_VentralAttention_A  Salience_VentralAttention_A\n",
      "4951    15            QL           O2R       -0.000857               Visual_Central            Visual_Peripheral\n",
      "7037    16         PALLL           T2L       -0.000793                Basal_Ganglia    DefaultMode_VentralMedial\n",
      "7105    17         PALLR         CER6R       -0.000784                Basal_Ganglia            Visual_Peripheral\n",
      "1348    18        F3O_2L         CER9L       -0.000779    DefaultMode_VentralMedial                   Cerebellum\n",
      "1832    19          SMAL         tVPLR       -0.000776  Salience_VentralAttention_A       Background/NonCortical\n",
      "5515    20           O2R         FUSIR       -0.000766            Visual_Peripheral            Visual_Peripheral\n",
      "[INFO] [SALIENCY] Completo. Resultados en resultados_13_paper/fold_1/interpretability_mlp\n"
     ]
    }
   ],
   "source": [
    "!python interpretar_fold_paper.py saliency \\\n",
    "  --run_dir ./resultados_13_paper \\\n",
    "  --fold 1 \\\n",
    "  --clf mlp \\\n",
    "  --global_tensor_path /home/diego/Escritorio/limpio/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz \\\n",
    "  --metadata_path /home/diego/Escritorio/limpio/SubjectsData_AAL3_procesado.csv \\\n",
    "  --roi_annotation_path \"/home/diego/Escritorio/limpio/roi_info_master.csv\" \\\n",
    "  --channels_to_use 1 2 5 \\\n",
    "  --latent_dim 512 \\\n",
    "  --latent_features_type mu \\\n",
    "  --metadata_features Age Sex \\\n",
    "  --num_conv_layers_encoder 4 \\\n",
    "  --decoder_type convtranspose \\\n",
    "  --dropout_rate_vae 0.2 \\\n",
    "  --intermediate_fc_dim_vae quarter \\\n",
    "  --vae_final_activation tanh \\\n",
    "  --saliency_method \"integrated_gradients\" \\\n",
    "  --top_k 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f07f4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda Notebook: violin para Age y latentes usando el shap_pack ===\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "from pathlib import Path\n",
    "import joblib, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap, re\n",
    "\n",
    "RUN_DIR = Path(\"./resultados_13_paper\")\n",
    "FOLD    = 1\n",
    "CLF     = \"mlp\"\n",
    "\n",
    "pack = joblib.load(RUN_DIR / f\"fold_{FOLD}/interpretability_shap/shap_pack_{CLF}.joblib\")\n",
    "shap_vals = pack[\"shap_values\"]            # (N,F) para clase positiva\n",
    "Xtest     = pack[\"X_test\"]                 # DataFrame post-preproc\n",
    "featnames = list(map(str, pack[\"feature_names\"]))\n",
    "\n",
    "# Máscaras robustas\n",
    "latent_mask = np.array([re.search(r'(?:^|__)latent_\\d+\\b', c) is not None for c in featnames])\n",
    "age_mask    = np.array([re.search(r'(?:^|__)Age\\b', c) is not None for c in featnames])\n",
    "\n",
    "# === Age solo (violin) ===\n",
    "if age_mask.any():\n",
    "    plt.figure(figsize=(6, 2.8))\n",
    "    shap.summary_plot(shap_vals[:, age_mask], Xtest.loc[:, age_mask],\n",
    "                      plot_type=\"violin\", show=False, max_display=1)\n",
    "    plt.title(f\"SHAP – Age (violin) · Fold {FOLD} · {CLF.upper()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RUN_DIR / f\"fold_{FOLD}/interpretability_shap/shap_age_violin.png\", dpi=150)\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"⚠️ 'Age' no está entre las columnas de X_test (puede que el selector la haya removido).\")\n",
    "\n",
    "# === Latentes solo (violin + beeswarm) ===\n",
    "if latent_mask.any():\n",
    "    Xlat = Xtest.loc[:, latent_mask]\n",
    "    S_lat = shap_vals[:, latent_mask]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.summary_plot(S_lat, Xlat, plot_type=\"violin\", show=False, max_display=20)\n",
    "    plt.title(f\"SHAP – Latent features (violin) · Fold {FOLD} · {CLF.upper()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RUN_DIR / f\"fold_{FOLD}/interpretability_shap/shap_latents_violin.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.summary_plot(S_lat, Xlat, show=False, max_display=20)\n",
    "    plt.title(f\"SHAP – Latent features (beeswarm) · Fold {FOLD} · {CLF.upper()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RUN_DIR / f\"fold_{FOLD}/interpretability_shap/shap_latents_beeswarm.png\", dpi=150)\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"⚠️ No se detectaron columnas latentes ('latent_*').\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "serentipia_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
